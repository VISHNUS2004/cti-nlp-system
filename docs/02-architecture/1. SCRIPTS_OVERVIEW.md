# CTI-NLP Training Scripts Overview

This document describes the utility scripts responsible for data preprocessing, model training, evaluation, and data ingestion for the CTI-NLP system.

---

## Folder: `scripts/`

```
scripts/
├── train_threat_classifier.py      # Train basic threat classification model
├── train_severity_model.py         # Train basic severity prediction model
├── train_ner_transformer.py        # Train transformer-based NER model
├── train_improved_models.py        # Train enhanced model variants
├── train_advanced_classifier.py    # Train advanced classification models
├── train_advanced_severity_predictor.py # Train advanced severity models
├── comprehensive_model_evaluation.py    # Comprehensive model testing
├── statistical_analysis.py         # Statistical analysis and visualization
├── enhanced_cybersecurity_ner.py   # Enhanced NER for cybersecurity
├── prepare_ner_data.py             # Prepare data for NER training
├── preprocess.py                   # Data preprocessing utilities
├── ingest_all_sources.py           # Data ingestion from multiple sources
└── train_ner_model.py              # Legacy NER training script
```

---

## Core Training Scripts

### `train_threat_classifier.py`

**Function:**

- Trains a classifier to predict threat type (e.g., Phishing, Malware)
- Uses TF-IDF vectorization + Logistic Regression

**Input:**

- File: `Cybersecurity_Dataset.csv`
- Required Columns: `Cleaned Threat Description`, `Threat Category`

**Output:**

- `models/threat_classifier.pkl`
- `models/tfidf_vectorizer.pkl`

### `train_severity_model.py`

### `train_severity_model.py`

**Function:**

- Trains a severity prediction model (Low, Medium, High)
- Uses TF-IDF + Random Forest classifier

**Input:**

- File: `Cybersecurity_Dataset.csv`
- Required Columns: `Cleaned Threat Description`, `Severity Score`

**Output:**

- `models/severity_model.pkl`
- `models/severity_vectorizer.pkl`

---

## Enhanced Training Scripts

### `train_improved_models.py`

**Function:**

- Trains enhanced versions of all models with better parameters
- Includes ensemble methods and advanced feature engineering

### `comprehensive_model_evaluation.py`

**Function:**

- Evaluates 22 different model combinations
- Provides comprehensive performance metrics
- Generates academic-quality comparison reports

### `statistical_analysis.py`

**Function:**

- Performs statistical analysis of model performance
- Generates visualizations and publication-ready tables
- Statistical significance testing

---

## Data Processing Scripts

### `prepare_ner_data.py`

**Function:**

- Prepares data for NER model training
- Converts datasets to proper NER format

### `preprocess.py`

**Function:**

- General data preprocessing utilities
- Text cleaning and normalization

### `ingest_all_sources.py`

**Function:**

- Ingests data from multiple external sources
- Handles data integration and deduplication

---

## Usage

Run scripts from the project root directory:

```bash
# Basic model training
python scripts/train_threat_classifier.py
python scripts/train_severity_model.py

# Enhanced model training
python scripts/train_improved_models.py

# Model evaluation
python scripts/comprehensive_model_evaluation.py

# Data processing
python scripts/prepare_ner_data.py
python scripts/ingest_all_sources.py
```

All output models are saved in the `/models` directory.
Dataset files should be placed in the `/data` directory.

## Tips

- Always inspect `df.columns` and `df.head()` before training
- Modify scripts to change model architecture, hyperparameters, or data source
- Add logs or `argparse` if multiple datasets or configs are needed

---

## Maintainers

- Sanjan Acharya & Team
- 2025 Major Project @ ATME AI & ML Dept.
